{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T16:10:45.734916Z",
     "iopub.status.busy": "2023-07-23T16:10:45.734785Z",
     "iopub.status.idle": "2023-07-23T16:10:50.935822Z",
     "shell.execute_reply": "2023-07-23T16:10:50.935418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:08:06.583358: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-22 00:08:06.583384: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-22 00:08:06.583401: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-22 00:08:08.172459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T16:10:51.149492Z",
     "iopub.status.busy": "2023-07-23T16:10:51.149315Z",
     "iopub.status.idle": "2023-07-23T16:10:56.956722Z",
     "shell.execute_reply": "2023-07-23T16:10:56.956193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8175\n",
      "[ 103   99   42  170   43  109   54 1453 1782 5719  106   42   54 2817\n",
      " 6631 1320   17   95 1775  797 1920  102   95  109  138  322  106  168\n",
      "  368  149   96  966  106  196  175  201   17  104  447 3240  196    5\n",
      "  797  333    5  104  124  302  119  592   98 1167   17   31  100   18\n",
      "   33   31  100   18   33   95  293  104   95  112   99  115  267   42\n",
      "   54 2817 6631 1320   99   95  324   97  101   10   60  854   17   95\n",
      "  112   99  115  266   17   95  112   99  115 1507   17   95  112  252\n",
      "   10   61  119  334 7399   98  231  135   95 1775 1140   17  101   10\n",
      "   60  115  151  706   60 6449 4300   17  234  131   10   60   60 3674\n",
      " 2676  493]\n",
      "this is a bad b movie masquerading as a mockumentary . the porn documentary filmmaker in the movie has almost as much screen time and dialog as any other character . that completely destroyed any \" documentary feel \" that they may have wanted to create . < br / > < br / > the fact that the film is not actually a mockumentary is the least of it ' s problems . the film is not funny . the film is not sexy . the film doesn ' t have anything insightful to say about the porn business . it ' s not even particularly salacious . while there ' s simulated sex\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=8192, max_seq_len=128)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T16:10:56.958484Z",
     "iopub.status.busy": "2023-07-23T16:10:56.958280Z",
     "iopub.status.idle": "2023-07-23T16:35:06.541711Z",
     "shell.execute_reply": "2023-07-23T16:35:06.541331Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:17<00:00, 43.96batch/s, Loss = 0.4484, AUC = 87.38%]                                           \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:11<00:00, 67.02batch/s, Loss = 0.4279, AUC = 88.86%]                                           \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:08<00:00, 87.70batch/s, Loss = 0.4512, AUC = 88.21%]                                           \n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:12<00:00, 62.32batch/s, Loss = 0.5313, AUC = 87.24%]                                           \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:12<00:00, 63.49batch/s, Loss = 0.6314, AUC = 86.86%]                                           \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:10<00:00, 72.41batch/s, Loss = 0.7760, AUC = 85.63%]                                           \n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:11<00:00, 65.66batch/s, Loss = 0.9031, AUC = 85.02%]                                           \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:09<00:00, 84.98batch/s, Loss = 1.1330, AUC = 82.28%]                                           \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:11<00:00, 69.50batch/s, Loss = 1.0283, AUC = 83.49%]                                           \n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:13<00:00, 57.97batch/s, Loss = 1.1310, AUC = 81.22%]                                           \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:09<00:00, 83.88batch/s, Loss = 1.0545, AUC = 83.39%]                                           \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:11<00:00, 70.37batch/s, Loss = 1.1261, AUC = 82.59%]                                           \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:10<00:00, 73.21batch/s, Loss = 1.0683, AUC = 83.32%]                                           \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:10<00:00, 74.29batch/s, Loss = 1.1888, AUC = 79.83%]                                           \n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:13<00:00, 57.53batch/s, Loss = 1.1994, AUC = 81.94%]                                           \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 89.91batch/s, Loss = 1.1855, AUC = 82.20%]                                           \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:10<00:00, 71.77batch/s, Loss = 1.1928, AUC = 80.78%]                                           \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:11<00:00, 65.87batch/s, Loss = 1.2536, AUC = 81.64%]                                           \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:11<00:00, 70.10batch/s, Loss = 1.1758, AUC = 83.95%]                                           \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:12<00:00, 64.68batch/s, Loss = 1.2633, AUC = 82.31%]                                           \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:10<00:00, 71.79batch/s, Loss = 1.3771, AUC = 82.03%]                                           \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:09<00:00, 81.32batch/s, Loss = 1.4170, AUC = 79.77%]                                           \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:13<00:00, 59.72batch/s, Loss = 1.3787, AUC = 83.69%]                                           \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:12<00:00, 62.91batch/s, Loss = 1.3917, AUC = 82.13%]                                           \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 98.28batch/s, Loss = 1.4459, AUC = 83.48%]                                           \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:10<00:00, 71.13batch/s, Loss = 1.3301, AUC = 84.75%]                                           \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:08<00:00, 89.60batch/s, Loss = 1.2777, AUC = 84.11%]                                           \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:10<00:00, 74.66batch/s, Loss = 1.6399, AUC = 83.90%]                                           \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:10<00:00, 71.69batch/s, Loss = 1.4595, AUC = 84.40%]                                           \n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:08<00:00, 91.07batch/s, Loss = 1.5709, AUC = 84.26%]                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 333.14s\n",
      "BEST AUC = 88.86% AT EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=128, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=0.0003, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T16:35:06.543341Z",
     "iopub.status.busy": "2023-07-23T16:35:06.543203Z",
     "iopub.status.idle": "2023-07-23T16:57:14.586605Z",
     "shell.execute_reply": "2023-07-23T16:57:14.586095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:15<00:00, 49.38batch/s, Loss = 0.6901, AUC = 54.42%]                                           \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:11<00:00, 65.75batch/s, Loss = 0.6811, AUC = 58.78%]                                           \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:11<00:00, 66.17batch/s, Loss = 0.6666, AUC = 63.20%]                                           \n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:10<00:00, 75.04batch/s, Loss = 0.6544, AUC = 67.19%]                                           \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:12<00:00, 60.41batch/s, Loss = 0.6271, AUC = 70.58%]                                           \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:10<00:00, 78.06batch/s, Loss = 0.6107, AUC = 73.23%]                                           \n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:11<00:00, 67.63batch/s, Loss = 0.5976, AUC = 75.21%]                                           \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:12<00:00, 64.92batch/s, Loss = 0.5899, AUC = 76.63%]                                           \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:10<00:00, 74.83batch/s, Loss = 0.5779, AUC = 77.74%]                                           \n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:13<00:00, 58.96batch/s, Loss = 0.5828, AUC = 78.57%]                                           \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:10<00:00, 71.85batch/s, Loss = 0.5824, AUC = 79.17%]                                           \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:10<00:00, 71.68batch/s, Loss = 0.5826, AUC = 79.52%]                                           \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:13<00:00, 57.25batch/s, Loss = 0.5766, AUC = 79.88%]                                           \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:10<00:00, 78.01batch/s, Loss = 0.5789, AUC = 80.10%]                                           \n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:11<00:00, 65.56batch/s, Loss = 0.5811, AUC = 80.23%]                                           \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:11<00:00, 66.12batch/s, Loss = 0.6058, AUC = 80.34%]                                           \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:10<00:00, 75.12batch/s, Loss = 0.6100, AUC = 80.51%]                                           \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:12<00:00, 60.30batch/s, Loss = 0.6330, AUC = 80.47%]                                           \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:09<00:00, 83.29batch/s, Loss = 0.6186, AUC = 80.60%]                                           \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:10<00:00, 77.49batch/s, Loss = 0.6262, AUC = 80.43%]                                           \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 94.93batch/s, Loss = 0.6652, AUC = 80.29%]                                           \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:08<00:00, 88.61batch/s, Loss = 0.6548, AUC = 80.63%]                                           \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:10<00:00, 71.92batch/s, Loss = 0.6779, AUC = 80.53%]                                           \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:07<00:00, 102.29batch/s, Loss = 0.6853, AUC = 80.57%]                                          \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:09<00:00, 79.08batch/s, Loss = 0.6988, AUC = 80.16%]                                           \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:10<00:00, 74.17batch/s, Loss = 0.7052, AUC = 80.54%]                                           \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 100.05batch/s, Loss = 0.7364, AUC = 80.49%]                                          \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:08<00:00, 88.77batch/s, Loss = 0.7398, AUC = 80.23%]                                           \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:09<00:00, 85.02batch/s, Loss = 0.7483, AUC = 80.40%]                                           \n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 100.04batch/s, Loss = 0.7486, AUC = 80.19%]                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 321.63s\n",
      "BEST AUC = 80.63% AT EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=128, num_classes=2, hidden_size=6, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=3)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=0.0003, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "gsoc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
