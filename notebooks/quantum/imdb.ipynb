{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Reviews (Quantum)\n",
    "\n",
    "This notebook trains and evaluates a quantum transformer for the IMDb Reviews sentiment classification task. Note that this is a text classification task.\n",
    "You can find information about the dataset at https://www.tensorflow.org/datasets/catalog/imdb_reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:23:18.422798Z",
     "iopub.status.busy": "2023-10-09T22:23:18.422674Z",
     "iopub.status.idle": "2023-10-09T22:23:29.124548Z",
     "shell.execute_reply": "2023-10-09T22:23:29.124133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:23:21.880365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-09 15:23:21.880392: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-09 15:23:21.880411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-09 15:23:23.718721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "from quantum_transformers.quantum_layer import get_circuit\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are trained using the following devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:23:29.126883Z",
     "iopub.status.busy": "2023-10-09T22:23:29.126510Z",
     "iopub.status.idle": "2023-10-09T22:23:29.334752Z",
     "shell.execute_reply": "2023-10-09T22:23:29.334351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how big is the vocabulary, and see an example of one example review (both in tokenized and raw form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:23:29.336517Z",
     "iopub.status.busy": "2023-10-09T22:23:29.336376Z",
     "iopub.status.idle": "2023-10-09T22:25:08.033572Z",
     "shell.execute_reply": "2023-10-09T22:25:08.033125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinalities (train, val, test): 22500 2500 25000\n",
      "Vocabulary size: 19769\n",
      "[  129    50   397   183    42  1734   940    17   101   163   495   163\n",
      "  1023    96   163   270    17    50   510   376   102   103   109    17\n",
      "   259   183   433   121   298   110    95 13096   586    17  7746  7130\n",
      "    99   177   102   103    96    50    10    54   576   240   267   109\n",
      "   108   131   102   104    50   142   167   152  1042   113    17   163\n",
      "   381    42   259    17     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "like i said its a hidden surprise . it well written well acted and well cast . i liked everything in this movie . look its hollywood all right but the brighter side . angelina jolie is great in this and i ' m totally watching every movie with her in that i can get my hands on . well worth a look . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader, imdb_test_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the quantum vision transformer on the best hyperparameters found using random hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T22:25:08.035283Z",
     "iopub.status.busy": "2023-10-09T22:25:08.035136Z",
     "iopub.status.idle": "2023-10-09T23:00:53.539551Z",
     "shell.execute_reply": "2023-10-09T23:00:53.539071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters = 122096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 703/703 [01:44<00:00,  6.76batch/s, Loss = 0.6954, AUC = 49.56%]\n",
      "Epoch   2/30: 100%|██████████| 703/703 [01:09<00:00, 10.18batch/s, Loss = 0.6930, AUC = 50.92%]\n",
      "Epoch   3/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.6907, AUC = 58.98%]\n",
      "Epoch   4/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.6861, AUC = 69.50%]\n",
      "Epoch   5/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.6691, AUC = 71.83%]\n",
      "Epoch   6/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.6076, AUC = 78.95%]\n",
      "Epoch   7/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.5150, AUC = 85.68%]\n",
      "Epoch   8/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.4528, AUC = 87.83%]\n",
      "Epoch   9/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.4179, AUC = 89.23%]\n",
      "Epoch  10/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.4574, AUC = 89.75%]\n",
      "Epoch  11/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.5260, AUC = 88.06%]\n",
      "Epoch  12/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.3934, AUC = 90.94%]\n",
      "Epoch  13/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.4198, AUC = 91.13%]\n",
      "Epoch  14/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.4256, AUC = 91.43%]\n",
      "Epoch  15/30: 100%|██████████| 703/703 [01:09<00:00, 10.15batch/s, Loss = 0.5088, AUC = 91.02%]\n",
      "Epoch  16/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.4728, AUC = 91.42%]\n",
      "Epoch  17/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.5283, AUC = 91.34%]\n",
      "Epoch  18/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.5115, AUC = 91.44%]\n",
      "Epoch  19/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.5076, AUC = 91.63%]\n",
      "Epoch  20/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.6286, AUC = 91.65%]\n",
      "Epoch  21/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.6293, AUC = 91.64%]\n",
      "Epoch  22/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 0.6728, AUC = 91.44%]\n",
      "Epoch  23/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.8458, AUC = 91.63%]\n",
      "Epoch  24/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 1.0611, AUC = 91.22%]\n",
      "Epoch  25/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 0.8356, AUC = 91.69%]\n",
      "Epoch  26/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 1.0028, AUC = 91.40%]\n",
      "Epoch  27/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 1.1744, AUC = 91.23%]\n",
      "Epoch  28/30: 100%|██████████| 703/703 [01:09<00:00, 10.19batch/s, Loss = 1.1097, AUC = 91.13%]\n",
      "Epoch  29/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 1.1374, AUC = 91.31%]\n",
      "Epoch  30/30: 100%|██████████| 703/703 [01:08<00:00, 10.19batch/s, Loss = 1.1246, AUC = 91.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time = 2105.31s, best validation AUC = 91.69% at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 781/781 [00:28<00:00, 26.94batch/s, Loss = 0.9679, AUC = 89.46%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array(0.96788067, dtype=float32),\n",
       " 89.45922399288703,\n",
       " array([0.00000000e+00, 0.00000000e+00, 2.40038406e-04, ...,\n",
       "        9.99679949e-01, 9.99679949e-01, 1.00000000e+00]),\n",
       " array([0.        , 0.00760365, 0.01816872, ..., 0.99991996, 1.        ,\n",
       "        1.        ]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=6, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=3,\n",
    "                    quantum_attn_circuit=get_circuit(), quantum_mlp_circuit=get_circuit())\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, imdb_test_dataloader, num_classes=2, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
