{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T21:23:50.850783Z",
     "iopub.status.busy": "2023-08-26T21:23:50.850675Z",
     "iopub.status.idle": "2023-08-26T21:24:10.710642Z",
     "shell.execute_reply": "2023-08-26T21:24:10.710130Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 14:23:52.983199: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-26 14:23:52.983226: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-26 14:23:52.983244: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-26 14:23:55.659448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')  # Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.random.set_seed(42)  # For reproducibility.\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T21:24:10.712965Z",
     "iopub.status.busy": "2023-08-26T21:24:10.712603Z",
     "iopub.status.idle": "2023-08-26T21:24:11.019041Z",
     "shell.execute_reply": "2023-08-26T21:24:11.018517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T21:24:11.020877Z",
     "iopub.status.busy": "2023-08-26T21:24:11.020701Z",
     "iopub.status.idle": "2023-08-26T21:25:40.192472Z",
     "shell.execute_reply": "2023-08-26T21:25:40.191972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19169\n",
      "[  141  1693    15   139   161   123   631    34    34     4     4     4\n",
      "     4     4     4   218    99   220  1473  1848    15   150   241    50\n",
      "   180    10    61   193   101    10   329   156   645    17   112   478\n",
      "    10    61   119   414   103   514    97  1254   648    17    31   100\n",
      "    18    33    31   100    18    33    42   691    97   599   992  4916\n",
      " 12468   135   230  3431   192    42   691    97   156   472   169    15\n",
      "   126   230   113    42   156   472  2461   107   187    98   446    96\n",
      "   605   187    15    96    95  6665 17703   276   124  3424   187   510\n",
      "   136   158   156   472  5741    17   102   172   803    15    95   315\n",
      "   243    99   156   472    17    31   100    18    33    31   100    18\n",
      "    33   112   213   101   138    98   119   167   145   150  2019    96\n",
      "    95 15091   142    10    61   699   232     4     4    96   123   251\n",
      "    10    61     4    50   213    15   140    97   158   509   161   256\n",
      "    15   129   139    98   858    98    95  2070     5   661     5    96\n",
      "    95   599   887    15   110    15 15725    15   103   105   277  2156\n",
      "  1090   710    17    31   100    18    33    31   100    18    33   121\n",
      "    50   142   224    99   171   114   196   103   514    56 15646    17\n",
      "   101    99   114   386   220   613    17     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "good lord , what were they thinking ? ? ! ! ! ! ! ! here is your spoiler warning , even though i don ' t think it ' ll really matter . you won ' t be seeing this piece of trash anyway . < br / > < br / > a group of handpuppets go chasing after a group of really stupid people , who go on a really stupid hunt for them to try and kill them , and the puppets complicate things by letting them live out their really stupid fantasies . in other words , the whole thing is really stupid . < br / > < br / > you know it has to be bad when even mike and the bots can ' t save something ! ! and they didn ' t ! i know , some of their lines were funny , like what to add to the sign \" hit \" and the hand comments , but , geez , this was pretty dang sad . < br / > < br / > all i can say is do not watch this piece o crud . it is not worth your eyes . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T21:25:40.194283Z",
     "iopub.status.busy": "2023-08-26T21:25:40.194098Z",
     "iopub.status.idle": "2023-08-26T21:30:07.004836Z",
     "shell.execute_reply": "2023-08-26T21:30:07.004240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:14<00:00, 54.11batch/s, Loss = 0.5339, AUC = 81.49%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:07<00:00, 101.17batch/s, Loss = 0.3689, AUC = 92.40%]\n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:08<00:00, 92.50batch/s, Loss = 0.3546, AUC = 93.78%] \n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:08<00:00, 95.83batch/s, Loss = 0.3589, AUC = 93.25%] \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:08<00:00, 87.27batch/s, Loss = 0.4364, AUC = 92.80%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:08<00:00, 93.92batch/s, Loss = 0.4988, AUC = 92.45%] \n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:08<00:00, 90.54batch/s, Loss = 0.5900, AUC = 92.11%] \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:08<00:00, 93.79batch/s, Loss = 0.6960, AUC = 91.64%] \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 98.40batch/s, Loss = 0.7159, AUC = 91.89%] \n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:08<00:00, 96.17batch/s, Loss = 0.7524, AUC = 92.15%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:08<00:00, 93.06batch/s, Loss = 0.7697, AUC = 91.77%] \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:08<00:00, 94.42batch/s, Loss = 0.8723, AUC = 91.56%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:08<00:00, 88.12batch/s, Loss = 0.9211, AUC = 92.06%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:08<00:00, 90.01batch/s, Loss = 1.2101, AUC = 91.72%] \n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:08<00:00, 93.73batch/s, Loss = 0.9038, AUC = 91.84%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 91.67batch/s, Loss = 1.1028, AUC = 91.54%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:08<00:00, 91.76batch/s, Loss = 0.9858, AUC = 91.80%] \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:08<00:00, 90.95batch/s, Loss = 0.8417, AUC = 91.61%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:08<00:00, 94.88batch/s, Loss = 1.0331, AUC = 91.44%] \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:08<00:00, 93.80batch/s, Loss = 0.9018, AUC = 91.61%] \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 95.11batch/s, Loss = 1.1636, AUC = 91.11%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:08<00:00, 95.68batch/s, Loss = 1.1112, AUC = 91.21%] \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:08<00:00, 89.64batch/s, Loss = 1.1976, AUC = 91.32%] \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:08<00:00, 96.31batch/s, Loss = 1.1507, AUC = 91.48%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:08<00:00, 97.36batch/s, Loss = 1.2652, AUC = 90.15%] \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:08<00:00, 97.19batch/s, Loss = 1.4640, AUC = 90.86%] \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 100.67batch/s, Loss = 1.2885, AUC = 90.66%]\n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:07<00:00, 98.19batch/s, Loss = 1.1268, AUC = 90.44%] \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:08<00:00, 92.41batch/s, Loss = 1.3645, AUC = 89.91%] \n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 101.07batch/s, Loss = 1.2595, AUC = 90.82%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 254.92s\n",
      "BEST AUC = 93.78% AT EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T21:30:07.010383Z",
     "iopub.status.busy": "2023-08-26T21:30:07.010241Z",
     "iopub.status.idle": "2023-08-26T21:34:03.711228Z",
     "shell.execute_reply": "2023-08-26T21:34:03.710694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:12<00:00, 62.07batch/s, Loss = 0.6888, AUC = 57.67%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:08<00:00, 97.50batch/s, Loss = 0.6066, AUC = 75.48%] \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:07<00:00, 109.84batch/s, Loss = 0.5296, AUC = 82.00%]\n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:07<00:00, 104.95batch/s, Loss = 0.4731, AUC = 86.15%]\n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:07<00:00, 99.50batch/s, Loss = 0.4360, AUC = 88.55%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:06<00:00, 112.30batch/s, Loss = 0.4787, AUC = 89.54%]\n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:07<00:00, 103.77batch/s, Loss = 0.4284, AUC = 90.72%]\n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 100.28batch/s, Loss = 0.4367, AUC = 91.47%]\n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 102.80batch/s, Loss = 0.5624, AUC = 91.63%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:07<00:00, 99.22batch/s, Loss = 0.4924, AUC = 91.41%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:07<00:00, 97.97batch/s, Loss = 0.6339, AUC = 91.60%] \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:08<00:00, 97.42batch/s, Loss = 0.6597, AUC = 91.66%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:08<00:00, 94.33batch/s, Loss = 0.6514, AUC = 91.42%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:07<00:00, 102.12batch/s, Loss = 0.6532, AUC = 91.42%]\n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:07<00:00, 100.19batch/s, Loss = 0.7032, AUC = 91.03%]\n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 95.63batch/s, Loss = 0.8119, AUC = 91.11%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:07<00:00, 101.86batch/s, Loss = 0.8977, AUC = 90.73%]\n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:07<00:00, 99.56batch/s, Loss = 0.9033, AUC = 89.11%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:06<00:00, 111.97batch/s, Loss = 1.0243, AUC = 85.60%]\n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:07<00:00, 111.49batch/s, Loss = 1.0671, AUC = 83.84%]\n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:07<00:00, 104.35batch/s, Loss = 1.0403, AUC = 83.98%]\n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:08<00:00, 95.66batch/s, Loss = 1.1694, AUC = 78.43%] \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:07<00:00, 109.17batch/s, Loss = 1.2027, AUC = 83.85%]\n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:08<00:00, 97.10batch/s, Loss = 1.2235, AUC = 85.21%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 99.98batch/s, Loss = 1.3095, AUC = 84.17%] \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:07<00:00, 106.25batch/s, Loss = 1.3583, AUC = 87.15%]\n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 111.19batch/s, Loss = 1.3424, AUC = 88.75%]\n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:06<00:00, 115.51batch/s, Loss = 1.3896, AUC = 88.27%]\n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:07<00:00, 101.74batch/s, Loss = 1.4969, AUC = 88.52%]\n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:08<00:00, 95.62batch/s, Loss = 1.5694, AUC = 88.70%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 233.78s\n",
      "BEST AUC = 91.66% AT EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=8, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=4)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
