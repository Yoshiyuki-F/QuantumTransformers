{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T16:40:24.211840Z",
     "iopub.status.busy": "2023-08-26T16:40:24.211551Z",
     "iopub.status.idle": "2023-08-26T16:40:41.900788Z",
     "shell.execute_reply": "2023-08-26T16:40:41.900390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 09:40:25.491928: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-26 09:40:25.491958: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-26 09:40:25.491974: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-26 09:40:27.873842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')  # Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.random.set_seed(42)  # For reproducibility.\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T16:40:41.903050Z",
     "iopub.status.busy": "2023-08-26T16:40:41.902702Z",
     "iopub.status.idle": "2023-08-26T16:40:42.314781Z",
     "shell.execute_reply": "2023-08-26T16:40:42.314366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T16:40:42.316532Z",
     "iopub.status.busy": "2023-08-26T16:40:42.316389Z",
     "iopub.status.idle": "2023-08-26T16:42:19.801481Z",
     "shell.execute_reply": "2023-08-26T16:42:19.800934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19169\n",
      "[  141  1693    15   139   161   123   631    34    34     4     4     4\n",
      "     4     4     4   218    99   220  1473  1848    15   150   241    50\n",
      "   180    10    61   193   101    10   329   156   645    17   112   478\n",
      "    10    61   119   414   103   514    97  1254   648    17    31   100\n",
      "    18    33    31   100    18    33    42   691    97   599   992  4916\n",
      " 12468   135   230  3431   192    42   691    97   156   472   169    15\n",
      "   126   230   113    42   156   472  2461   107   187    98   446    96\n",
      "   605   187    15    96    95  6665 17703   276   124  3424   187   510\n",
      "   136   158   156   472  5741    17   102   172   803    15    95   315\n",
      "   243    99   156   472    17    31   100    18    33    31   100    18\n",
      "    33   112   213   101   138    98   119   167   145   150  2019    96\n",
      "    95 15091   142    10    61   699   232     4     4    96   123   251\n",
      "    10    61     4    50   213    15   140    97   158   509   161   256\n",
      "    15   129   139    98   858    98    95  2070     5   661     5    96\n",
      "    95   599   887    15   110    15 15725    15   103   105   277  2156\n",
      "  1090   710    17    31   100    18    33    31   100    18    33   121\n",
      "    50   142   224    99   171   114   196   103   514    56 15646    17\n",
      "   101    99   114   386   220   613    17     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "good lord , what were they thinking ? ? ! ! ! ! ! ! here is your spoiler warning , even though i don ' t think it ' ll really matter . you won ' t be seeing this piece of trash anyway . < br / > < br / > a group of handpuppets go chasing after a group of really stupid people , who go on a really stupid hunt for them to try and kill them , and the puppets complicate things by letting them live out their really stupid fantasies . in other words , the whole thing is really stupid . < br / > < br / > you know it has to be bad when even mike and the bots can ' t save something ! ! and they didn ' t ! i know , some of their lines were funny , like what to add to the sign \" hit \" and the hand comments , but , geez , this was pretty dang sad . < br / > < br / > all i can say is do not watch this piece o crud . it is not worth your eyes . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T16:42:19.803349Z",
     "iopub.status.busy": "2023-08-26T16:42:19.803153Z",
     "iopub.status.idle": "2023-08-26T16:46:36.710895Z",
     "shell.execute_reply": "2023-08-26T16:46:36.710359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:13<00:00, 58.05batch/s, Loss = 0.3615, AUC = 94.50%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:07<00:00, 101.30batch/s, Loss = 0.3606, AUC = 93.85%]\n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:08<00:00, 87.88batch/s, Loss = 0.4195, AUC = 93.02%] \n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:08<00:00, 93.48batch/s, Loss = 0.6730, AUC = 92.30%] \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:08<00:00, 91.74batch/s, Loss = 0.5989, AUC = 91.97%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:07<00:00, 100.84batch/s, Loss = 0.6869, AUC = 91.75%]\n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:07<00:00, 97.83batch/s, Loss = 0.7283, AUC = 91.95%] \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 98.27batch/s, Loss = 0.7275, AUC = 91.66%] \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 100.52batch/s, Loss = 0.8775, AUC = 90.32%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:08<00:00, 94.89batch/s, Loss = 0.6713, AUC = 91.42%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:08<00:00, 93.92batch/s, Loss = 0.7087, AUC = 91.33%] \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:08<00:00, 92.94batch/s, Loss = 0.9246, AUC = 91.15%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:08<00:00, 92.02batch/s, Loss = 0.9789, AUC = 90.96%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:07<00:00, 100.75batch/s, Loss = 1.0753, AUC = 90.91%]\n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:08<00:00, 91.12batch/s, Loss = 1.3153, AUC = 90.65%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 96.30batch/s, Loss = 0.9459, AUC = 90.79%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:08<00:00, 91.06batch/s, Loss = 1.0591, AUC = 91.19%] \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:08<00:00, 93.71batch/s, Loss = 1.1564, AUC = 90.61%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:08<00:00, 89.98batch/s, Loss = 1.1880, AUC = 90.82%] \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:07<00:00, 99.58batch/s, Loss = 1.4642, AUC = 90.96%] \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 94.30batch/s, Loss = 1.4784, AUC = 90.94%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:07<00:00, 100.94batch/s, Loss = 1.5098, AUC = 90.92%]\n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:07<00:00, 97.65batch/s, Loss = 1.5288, AUC = 90.91%] \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:08<00:00, 93.43batch/s, Loss = 1.5550, AUC = 90.91%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 100.31batch/s, Loss = 1.5806, AUC = 90.89%]\n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:08<00:00, 90.90batch/s, Loss = 1.6090, AUC = 90.88%] \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 99.83batch/s, Loss = 1.6426, AUC = 90.85%] \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:08<00:00, 91.08batch/s, Loss = 1.6808, AUC = 90.83%] \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:07<00:00, 100.06batch/s, Loss = 1.7288, AUC = 90.79%]\n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:08<00:00, 96.25batch/s, Loss = 1.7669, AUC = 90.78%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 250.78s\n",
      "BEST AUC = 94.50% AT EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=1e-3, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T16:46:36.717088Z",
     "iopub.status.busy": "2023-08-26T16:46:36.716936Z",
     "iopub.status.idle": "2023-08-26T16:50:29.326560Z",
     "shell.execute_reply": "2023-08-26T16:50:29.326090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:11<00:00, 66.19batch/s, Loss = 0.4643, AUC = 86.81%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:07<00:00, 104.19batch/s, Loss = 0.4212, AUC = 90.47%]\n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:07<00:00, 104.45batch/s, Loss = 0.3881, AUC = 91.64%]\n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:07<00:00, 101.90batch/s, Loss = 0.4132, AUC = 92.01%]\n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:07<00:00, 97.80batch/s, Loss = 0.4625, AUC = 91.83%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:07<00:00, 107.63batch/s, Loss = 0.5175, AUC = 91.55%]\n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:06<00:00, 113.81batch/s, Loss = 0.5887, AUC = 91.30%]\n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 98.79batch/s, Loss = 0.6287, AUC = 91.10%] \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 103.13batch/s, Loss = 0.6738, AUC = 90.69%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:07<00:00, 110.06batch/s, Loss = 0.7465, AUC = 89.46%]\n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:07<00:00, 102.11batch/s, Loss = 0.7913, AUC = 88.73%]\n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:06<00:00, 112.94batch/s, Loss = 0.7889, AUC = 85.97%]\n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:07<00:00, 105.41batch/s, Loss = 0.8167, AUC = 85.68%]\n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:07<00:00, 109.87batch/s, Loss = 0.6942, AUC = 86.38%]\n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:07<00:00, 109.09batch/s, Loss = 0.7558, AUC = 85.75%]\n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 96.70batch/s, Loss = 0.9125, AUC = 80.88%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:07<00:00, 98.44batch/s, Loss = 0.8239, AUC = 82.26%] \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:07<00:00, 105.40batch/s, Loss = 0.8618, AUC = 82.61%]\n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:07<00:00, 98.28batch/s, Loss = 0.8692, AUC = 84.06%] \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:07<00:00, 109.17batch/s, Loss = 0.8852, AUC = 83.55%]\n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:07<00:00, 98.28batch/s, Loss = 0.8940, AUC = 83.40%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:07<00:00, 108.65batch/s, Loss = 1.0029, AUC = 82.60%]\n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:07<00:00, 97.93batch/s, Loss = 0.9959, AUC = 84.34%] \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:07<00:00, 106.73batch/s, Loss = 1.0076, AUC = 85.01%]\n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 102.57batch/s, Loss = 1.0874, AUC = 83.80%]\n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:07<00:00, 99.22batch/s, Loss = 1.0594, AUC = 86.75%] \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:08<00:00, 94.61batch/s, Loss = 1.0969, AUC = 86.64%] \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:07<00:00, 109.38batch/s, Loss = 1.1909, AUC = 86.52%]\n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:07<00:00, 108.46batch/s, Loss = 1.2434, AUC = 86.45%]\n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 109.66batch/s, Loss = 1.2336, AUC = 87.48%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 229.55s\n",
      "BEST AUC = 92.01% AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=8, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=4)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=1e-3, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
