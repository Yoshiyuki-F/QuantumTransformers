{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T15:09:15.906122Z",
     "iopub.status.busy": "2023-08-26T15:09:15.905983Z",
     "iopub.status.idle": "2023-08-26T15:09:25.718926Z",
     "shell.execute_reply": "2023-08-26T15:09:25.718455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 08:09:18.298717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-26 08:09:18.298744: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-26 08:09:18.298764: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-26 08:09:19.625187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T15:09:25.721403Z",
     "iopub.status.busy": "2023-08-26T15:09:25.721046Z",
     "iopub.status.idle": "2023-08-26T15:09:26.007261Z",
     "shell.execute_reply": "2023-08-26T15:09:26.006896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T15:09:26.008943Z",
     "iopub.status.busy": "2023-08-26T15:09:26.008808Z",
     "iopub.status.idle": "2023-08-26T15:11:07.211606Z",
     "shell.execute_reply": "2023-08-26T15:11:07.211191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19169\n",
      "[   50   524    10    61   356   104   103   109  6014   128  4286    15\n",
      "   101   159   121    95   364    97    42  2052    16   943  4244   281\n",
      "    16   598    17   251    10    61   123   118   191  2008    97   767\n",
      "   413   395   132  1795    34     4    34   251    10    61   123   213\n",
      "   104   102    95  1302    16  9488    95   660   102    42   521   281\n",
      "    16    96    18   132  6748    16   109   233   122   313   119    42\n",
      "   207   317  2319    34   132   211    50   166    95  1396   448    15\n",
      "   105   101   521    98   119    42  1021    96  3437   154    97   216\n",
      "    96  1722    15  2921   388   102    95   286  7680    97   201    15\n",
      "   132    42  1848    98  5098   114    98  1035   108   959    15   132\n",
      "   232   129   104    34    34   101   242    10    61   156   645    15\n",
      "   441   185   101   773   136   448    96    98   162   103   109  1301\n",
      "   113   121  7067    17    31   100    18    33    31   100    18    33\n",
      "   175    97   121    29    95   957    99   146  6921    17   137   122\n",
      "    42   442   148   112    10   245  2411    97  9125    42  1053   824\n",
      "    15   149  2047  3326  1743   152   474   117   146   175   499   683\n",
      "   108   291   613   122    95   264   148    15   104    10    60   581\n",
      " 18132    17    96    98   171   121   103   775   299  7013 16962    97\n",
      "    95  3225    34     4    96   226   113   768  2418   107   613   104\n",
      "   118    42   581  1865  1514   107  1828    15    96   186    95  1468\n",
      "   260   129    42  4079    34     4   124    95   185    15    50  2087\n",
      "   104   121    95   237 10097   102    95   109   159  7405    16   129\n",
      "  1357   557   613    15   524    10    61   123   118  4867   107   231\n",
      "    42 13927   338 10342  2975    34    95   154    99   926    15   101\n",
      "    10    60   134   103   433   318  7987   126   305   223  1006   824\n",
      "    16  9157   135    15   153  1182   259   179   322   129    95   180\n",
      "  1517    16  4006    11   132   122   313    15   104    10    60   139\n",
      "    50   186    97   101    12    96   184   115    10    60   202  4722\n",
      "   124   140  1345   431    17   353   103   325   317    99   737    17\n",
      "    50   477    15    50   142   487   104    95  1364    99  1024   102\n",
      "    95  2069    97    95  3046    11   933  1443   108   405    16  1896\n",
      "   824    16  1809     4    12   110   106    95  5063  1092   113  2833\n",
      "    97    95  1867  4778  6980    97    95  3225    15   101    10    60\n",
      "   812   162   226   123    10   245   136    98   605   179    17   226\n",
      "   114   655   179   677    96   260   107   252  3139  1652   245 10342\n",
      " 14494  1675    34    11    42 13546   236  1698   375    34    34    12\n",
      "    17    96   226   446    98   605   392   424   104    10    60   666\n",
      "   108   433  7987    15   309    10    61   104    42   317 19023    34\n",
      "     4   126    95   698   116   223    54  2958  6521  3793   648    15\n",
      "    50   542   114    95   272  1364   132    95  1434    15   123  4876\n",
      "   129 16528    15  1399   280    95  1666 10331  8616  3079    15  8550\n",
      "   236  2099 10372   129   123    10   245   192   140  1146  2630     6\n",
      "    20    15    96  8242   410    95  2257   212]\n",
      "i couldn ' t believe that this movie dates from 2007 , it had all the looks of a below - average seventies horror - flick . didn ' t they have any knowledge of modern special effects or cgi ? ! ? didn ' t they know that in the post - millennium the violence in a supposed horror - and / or scifi - movie should at least be a little bit graphic ? or did i get the purpose wrong , was it supposed to be a deep and meaningful story of man and animal , bound together in the big cycle of life , or a warning to mankind not to mess with nature , or something like that ? ? it doesn ' t really matter , either way it turned out wrong and to me this movie failed on all accounts . < br / > < br / > first of all : the premise is very improbable . if at a given time you ' re capable of replacing a total eye , no responsible medical scientist would start his very first human attempt with both eyes at the same time , that ' s totally unprofessional . and to do all this apparently without informed consent of the patient ? ! and why on earth choose for eyes that have a totally unusual color for humans , and make the victim look like a freak ? ! by the way , i noticed that all the real wolves in the movie had puppy - like normal dark eyes , couldn ' t they have waited for such a specimen ? the story is lame , it ' s about this poor guy aaron who gets these weird eye - transplants , which suddenly makes him feel like the donor - wolf ( or at least , that ' s what i make of it ) and then he ' s being chased by some military men . especially this last bit is ridiculous . i mean , i can understand that the army is interested in the results of the experiment ( imagine soldiers with night - vision eye - sight ! ) but as the operation fails on account of the apparent nervous breakdown of the patient , it ' s beyond me why they ' re out to kill him . why not leave him alone and look for another usable recipient ? ( a volunteering soldier maybe ? ? ) . and why try to kill everyone else that ' s involved with poor aaron , isn ' t that a bit steep ? ! who the hell are these militaries anyway , i hope not the us army or the government , they behave like psychopaths , walking around the hospital waving automatic weapons , raiding private apartments like they ' re after some public enemy # 1 , and displaying during the ultimate show\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T15:11:07.213598Z",
     "iopub.status.busy": "2023-08-26T15:11:07.213422Z",
     "iopub.status.idle": "2023-08-26T15:15:23.145956Z",
     "shell.execute_reply": "2023-08-26T15:15:23.145412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:13<00:00, 56.77batch/s, Loss = 0.3052, AUC = 94.65%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:08<00:00, 92.85batch/s, Loss = 0.3490, AUC = 93.86%] \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:07<00:00, 102.01batch/s, Loss = 0.4656, AUC = 92.78%]\n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:08<00:00, 96.42batch/s, Loss = 0.5610, AUC = 92.70%] \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:08<00:00, 93.76batch/s, Loss = 0.7049, AUC = 92.16%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:08<00:00, 95.12batch/s, Loss = 0.6877, AUC = 92.04%] \n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:07<00:00, 101.63batch/s, Loss = 0.7441, AUC = 92.24%]\n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 98.71batch/s, Loss = 0.8960, AUC = 91.88%] \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 100.10batch/s, Loss = 0.9671, AUC = 91.90%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:07<00:00, 98.87batch/s, Loss = 0.9740, AUC = 91.31%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:07<00:00, 101.91batch/s, Loss = 0.8698, AUC = 91.84%]\n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:07<00:00, 98.87batch/s, Loss = 1.0681, AUC = 91.50%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:08<00:00, 96.60batch/s, Loss = 0.7835, AUC = 90.82%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:08<00:00, 93.13batch/s, Loss = 0.7908, AUC = 91.23%] \n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:08<00:00, 90.73batch/s, Loss = 0.9407, AUC = 91.23%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 90.67batch/s, Loss = 1.2389, AUC = 90.31%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:07<00:00, 98.09batch/s, Loss = 0.9832, AUC = 90.35%] \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:08<00:00, 91.64batch/s, Loss = 0.9063, AUC = 89.55%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:08<00:00, 94.67batch/s, Loss = 0.8350, AUC = 90.12%] \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:08<00:00, 92.38batch/s, Loss = 1.0577, AUC = 90.57%] \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:07<00:00, 98.82batch/s, Loss = 0.6870, AUC = 86.08%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:07<00:00, 101.30batch/s, Loss = 0.6533, AUC = 79.79%]\n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:08<00:00, 91.77batch/s, Loss = 0.6469, AUC = 84.33%] \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:08<00:00, 94.71batch/s, Loss = 0.6427, AUC = 85.68%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:08<00:00, 94.28batch/s, Loss = 0.7894, AUC = 86.68%] \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:08<00:00, 91.97batch/s, Loss = 0.9108, AUC = 86.94%] \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:08<00:00, 94.32batch/s, Loss = 0.9621, AUC = 87.11%] \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:07<00:00, 97.87batch/s, Loss = 1.0162, AUC = 87.28%] \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:08<00:00, 93.41batch/s, Loss = 1.3990, AUC = 87.45%] \n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 100.20batch/s, Loss = 1.6081, AUC = 87.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 249.81s\n",
      "BEST AUC = 94.65% AT EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=1e-3, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T15:15:23.147719Z",
     "iopub.status.busy": "2023-08-26T15:15:23.147572Z",
     "iopub.status.idle": "2023-08-26T15:19:11.262915Z",
     "shell.execute_reply": "2023-08-26T15:19:11.262489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:11<00:00, 67.29batch/s, Loss = 0.4545, AUC = 87.17%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:07<00:00, 97.66batch/s, Loss = 0.3886, AUC = 90.82%] \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:06<00:00, 115.13batch/s, Loss = 0.3957, AUC = 91.52%]\n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:06<00:00, 114.57batch/s, Loss = 0.4172, AUC = 92.14%]\n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:07<00:00, 109.54batch/s, Loss = 0.4385, AUC = 91.94%]\n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:07<00:00, 104.68batch/s, Loss = 0.6222, AUC = 91.57%]\n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:07<00:00, 99.59batch/s, Loss = 0.5636, AUC = 91.01%] \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 105.52batch/s, Loss = 0.6665, AUC = 90.50%]\n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 111.31batch/s, Loss = 0.6564, AUC = 90.53%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:06<00:00, 112.17batch/s, Loss = 0.7334, AUC = 88.59%]\n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:06<00:00, 115.21batch/s, Loss = 0.7933, AUC = 87.02%]\n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:07<00:00, 108.07batch/s, Loss = 0.6923, AUC = 88.27%]\n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:07<00:00, 99.89batch/s, Loss = 0.7619, AUC = 86.59%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:07<00:00, 104.79batch/s, Loss = 0.8688, AUC = 81.40%]\n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:06<00:00, 113.00batch/s, Loss = 0.7861, AUC = 86.69%]\n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:07<00:00, 98.72batch/s, Loss = 0.7620, AUC = 85.33%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:07<00:00, 100.69batch/s, Loss = 0.8691, AUC = 83.61%]\n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:07<00:00, 99.20batch/s, Loss = 0.8976, AUC = 81.86%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:07<00:00, 99.75batch/s, Loss = 0.9303, AUC = 81.55%] \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:06<00:00, 113.97batch/s, Loss = 0.7525, AUC = 86.45%]\n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 97.39batch/s, Loss = 1.0056, AUC = 82.73%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:07<00:00, 102.94batch/s, Loss = 0.9514, AUC = 84.48%]\n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:06<00:00, 112.07batch/s, Loss = 1.0199, AUC = 84.37%]\n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:07<00:00, 110.42batch/s, Loss = 0.9668, AUC = 84.96%]\n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 104.72batch/s, Loss = 1.0172, AUC = 86.20%]\n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:07<00:00, 103.19batch/s, Loss = 1.5521, AUC = 78.52%]\n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 104.25batch/s, Loss = 1.1795, AUC = 86.24%]\n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:06<00:00, 111.90batch/s, Loss = 1.1684, AUC = 87.69%]\n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:07<00:00, 104.21batch/s, Loss = 1.1367, AUC = 87.30%]\n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:06<00:00, 112.65batch/s, Loss = 1.1859, AUC = 88.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 225.04s\n",
      "BEST AUC = 92.14% AT EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=8, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=4)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=1e-3, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
