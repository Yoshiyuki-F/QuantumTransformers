{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T14:57:09.020076Z",
     "iopub.status.busy": "2023-08-23T14:57:09.019960Z",
     "iopub.status.idle": "2023-08-23T14:57:20.266205Z",
     "shell.execute_reply": "2023-08-23T14:57:20.265803Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 07:57:12.087493: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-23 07:57:12.087514: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-23 07:57:12.087529: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-23 07:57:13.637538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T14:57:20.268450Z",
     "iopub.status.busy": "2023-08-23T14:57:20.268060Z",
     "iopub.status.idle": "2023-08-23T14:57:20.478019Z",
     "shell.execute_reply": "2023-08-23T14:57:20.477648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T14:57:20.479795Z",
     "iopub.status.busy": "2023-08-23T14:57:20.479588Z",
     "iopub.status.idle": "2023-08-23T14:58:55.076519Z",
     "shell.execute_reply": "2023-08-23T14:58:55.076088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19169\n",
      "[  103    99   125   417   109    17   106    42  2428   126  2235   147\n",
      "   108    42  4304  4516   165    97   101    99  1181    15    95  3590\n",
      "    15 13681   236    15  3897  2322    15  3476    96    95   129    17\n",
      "   101    99   864    98   285    95  1181   107  2655   110   192   239\n",
      "   103   111    42   263   303   101   138  2221   113   162    17    31\n",
      "   100    18    33    31   100    18    33    95   154    97  3222  7397\n",
      "    99   163   664    98   200 16932  1196    98   248  5785    96   972\n",
      "   637  4205   107  9998   236    95   154    17    31   100    18    33\n",
      "    31   100    18    33  3770   217   163  2424    42  1429   216    15\n",
      "    42   146   575   330    17  4069  5911  8326  8743    99  1436   102\n",
      "   131   175  1153   308    17    95   456    97    95   270    99  1255\n",
      "    17     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "this is an excellent movie . as a canadian who grew up with a rural lifestyle much of it is familiar , the winter , canoeing , trapping , hunting and the like . it is easy to take the familiar for granted but after watching this film a few times it has grown on me . < br / > < br / > the story of grey owl is well known to many canadians credit to director attenborough and screenplay writer nicholson for expanding the story . < br / > < br / > brosnan does well portraying a complex man , a very fine performance . annie galipeau is lovely in her first large role . the rest of the cast is solid . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T14:58:55.078322Z",
     "iopub.status.busy": "2023-08-23T14:58:55.078097Z",
     "iopub.status.idle": "2023-08-23T15:03:13.923369Z",
     "shell.execute_reply": "2023-08-23T15:03:13.922826Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:13<00:00, 57.76batch/s, Loss = 0.4160, AUC = 94.52%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:08<00:00, 93.10batch/s, Loss = 0.3185, AUC = 94.02%] \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:07<00:00, 101.48batch/s, Loss = 0.4248, AUC = 93.02%]\n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:08<00:00, 90.99batch/s, Loss = 0.4591, AUC = 92.47%] \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:08<00:00, 91.34batch/s, Loss = 0.6495, AUC = 92.13%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:07<00:00, 99.12batch/s, Loss = 0.7021, AUC = 91.63%] \n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:08<00:00, 93.70batch/s, Loss = 0.8267, AUC = 91.70%] \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 99.00batch/s, Loss = 0.6456, AUC = 91.46%] \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 100.28batch/s, Loss = 0.8326, AUC = 91.08%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:08<00:00, 92.55batch/s, Loss = 0.7619, AUC = 91.30%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:07<00:00, 98.95batch/s, Loss = 1.0457, AUC = 91.41%] \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:07<00:00, 99.27batch/s, Loss = 0.7639, AUC = 90.01%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:08<00:00, 92.87batch/s, Loss = 0.6862, AUC = 90.42%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:08<00:00, 95.97batch/s, Loss = 0.5704, AUC = 90.51%] \n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:08<00:00, 96.62batch/s, Loss = 0.5794, AUC = 89.05%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:07<00:00, 100.39batch/s, Loss = 0.5844, AUC = 89.94%]\n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:07<00:00, 99.44batch/s, Loss = 0.6606, AUC = 89.41%] \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:08<00:00, 95.16batch/s, Loss = 0.7791, AUC = 89.57%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:07<00:00, 98.72batch/s, Loss = 0.9317, AUC = 89.56%] \n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:08<00:00, 92.74batch/s, Loss = 1.1518, AUC = 89.51%] \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 94.71batch/s, Loss = 1.3381, AUC = 89.32%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:08<00:00, 90.95batch/s, Loss = 1.4159, AUC = 89.30%] \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:07<00:00, 100.07batch/s, Loss = 1.5198, AUC = 89.17%]\n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:07<00:00, 98.80batch/s, Loss = 1.5716, AUC = 89.14%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 98.45batch/s, Loss = 1.6722, AUC = 89.05%] \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:08<00:00, 95.41batch/s, Loss = 1.7510, AUC = 89.05%] \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:08<00:00, 95.01batch/s, Loss = 1.8118, AUC = 88.97%] \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:08<00:00, 96.56batch/s, Loss = 1.8994, AUC = 88.95%] \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:08<00:00, 91.53batch/s, Loss = 1.9822, AUC = 88.84%] \n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 97.88batch/s, Loss = 2.0457, AUC = 88.80%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 249.16s\n",
      "BEST AUC = 94.52% AT EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=1e-3, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T15:03:13.925506Z",
     "iopub.status.busy": "2023-08-23T15:03:13.925349Z",
     "iopub.status.idle": "2023-08-23T15:07:11.458396Z",
     "shell.execute_reply": "2023-08-23T15:07:11.457504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:11<00:00, 67.89batch/s, Loss = 0.5990, AUC = 76.40%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:08<00:00, 95.91batch/s, Loss = 0.4494, AUC = 88.58%] \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:07<00:00, 97.77batch/s, Loss = 0.4239, AUC = 90.84%] \n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:07<00:00, 106.89batch/s, Loss = 0.3592, AUC = 92.39%]\n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:08<00:00, 97.05batch/s, Loss = 0.3598, AUC = 92.72%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:07<00:00, 102.90batch/s, Loss = 0.3731, AUC = 92.69%]\n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:07<00:00, 101.70batch/s, Loss = 0.5376, AUC = 92.62%]\n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 102.76batch/s, Loss = 0.4675, AUC = 92.53%]\n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 105.32batch/s, Loss = 0.5070, AUC = 92.27%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:08<00:00, 96.80batch/s, Loss = 0.5855, AUC = 92.17%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:07<00:00, 106.21batch/s, Loss = 0.5785, AUC = 92.02%]\n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:07<00:00, 100.93batch/s, Loss = 0.6013, AUC = 92.05%]\n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:07<00:00, 100.74batch/s, Loss = 0.6556, AUC = 92.03%]\n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:07<00:00, 108.18batch/s, Loss = 0.6056, AUC = 92.06%]\n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:08<00:00, 96.43batch/s, Loss = 0.7198, AUC = 91.78%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:07<00:00, 98.33batch/s, Loss = 0.7090, AUC = 91.77%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:06<00:00, 113.13batch/s, Loss = 0.6916, AUC = 91.75%]\n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:07<00:00, 105.01batch/s, Loss = 0.6685, AUC = 91.98%]\n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:07<00:00, 102.55batch/s, Loss = 0.7022, AUC = 91.82%]\n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:07<00:00, 97.71batch/s, Loss = 0.7507, AUC = 91.74%] \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 96.57batch/s, Loss = 0.7664, AUC = 91.65%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:07<00:00, 98.35batch/s, Loss = 0.7104, AUC = 91.71%] \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:07<00:00, 102.88batch/s, Loss = 0.7312, AUC = 91.67%]\n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:08<00:00, 93.45batch/s, Loss = 0.7138, AUC = 91.73%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 100.77batch/s, Loss = 0.8138, AUC = 91.28%]\n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:07<00:00, 105.24batch/s, Loss = 0.7632, AUC = 91.47%]\n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 103.20batch/s, Loss = 0.8033, AUC = 91.32%]\n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:06<00:00, 111.95batch/s, Loss = 0.8055, AUC = 91.30%]\n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:07<00:00, 103.84batch/s, Loss = 0.7476, AUC = 91.53%]\n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 99.68batch/s, Loss = 0.8332, AUC = 90.70%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 234.49s\n",
      "BEST AUC = 92.72% AT EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=6, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=3)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, learning_rate=1e-3, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
