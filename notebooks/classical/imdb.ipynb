{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "\n",
    "Information about the dataset: https://www.tensorflow.org/datasets/catalog/imdb_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T14:21:06.102864Z",
     "iopub.status.busy": "2023-08-27T14:21:06.102632Z",
     "iopub.status.idle": "2023-08-27T14:21:16.814278Z",
     "shell.execute_reply": "2023-08-27T14:21:16.813860Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 07:21:06.859612: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-27 07:21:06.859651: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-27 07:21:06.859675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-27 07:21:07.853460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')  # Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.random.set_seed(42)  # For reproducibility.\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T14:21:16.816490Z",
     "iopub.status.busy": "2023-08-27T14:21:16.816117Z",
     "iopub.status.idle": "2023-08-27T14:21:17.191663Z",
     "shell.execute_reply": "2023-08-27T14:21:17.191251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T14:21:17.193460Z",
     "iopub.status.busy": "2023-08-27T14:21:17.193322Z",
     "iopub.status.idle": "2023-08-27T14:22:58.543423Z",
     "shell.execute_reply": "2023-08-27T14:22:58.542955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19769\n",
      "[  136    95  3739    97   103   111   159   182   192   674   122  7218\n",
      "   739    98    95   202    15   101   151   118   166   133   120   143\n",
      "   541    97   148    15   373    15    96  1664   875    17  3282    15\n",
      "   124  2883   121 13747    97   739    98    95  4431    15   123   118\n",
      "  1174    42  1885  6049    17   126   188  1483   147    42   111   102\n",
      "   153   125  1603  1915  2808    95   532   111   206   129   768  3960\n",
      "    15   706   108    95  2209  1589    61    16  3932    17   170   114\n",
      "  8124   103   111   106  1280    17     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "if the creators of this film had made any attempt at introducing reality to the plot , it would have been just one more waste of time , money , and creative effort . fortunately , by throwing all pretense of reality to the winds , they have created a comedic marvel . who could pass up a film in which an alien pilot spends the entire film acting like jack nicholson , complete with the lakers t - shirt . do not dismiss this film as trash . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_val_dataloader, imdb_test_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T14:22:58.545152Z",
     "iopub.status.busy": "2023-08-27T14:22:58.544948Z",
     "iopub.status.idle": "2023-08-27T14:25:29.648361Z",
     "shell.execute_reply": "2023-08-27T14:25:29.647891Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 703/703 [00:10<00:00, 65.29batch/s, Loss = 0.5371, AUC = 81.43%] \n",
      "Epoch   2/30: 100%|██████████| 703/703 [00:04<00:00, 157.47batch/s, Loss = 0.3601, AUC = 92.67%]\n",
      "Epoch   3/30: 100%|██████████| 703/703 [00:04<00:00, 158.32batch/s, Loss = 0.3100, AUC = 94.51%]\n",
      "Epoch   4/30: 100%|██████████| 703/703 [00:04<00:00, 156.87batch/s, Loss = 0.3042, AUC = 94.81%]\n",
      "Epoch   5/30: 100%|██████████| 703/703 [00:04<00:00, 155.62batch/s, Loss = 0.4049, AUC = 94.48%]\n",
      "Epoch   6/30: 100%|██████████| 703/703 [00:04<00:00, 160.08batch/s, Loss = 0.4603, AUC = 93.93%]\n",
      "Epoch   7/30: 100%|██████████| 703/703 [00:04<00:00, 158.13batch/s, Loss = 0.5529, AUC = 94.15%]\n",
      "Epoch   8/30: 100%|██████████| 703/703 [00:04<00:00, 158.78batch/s, Loss = 0.4452, AUC = 94.12%]\n",
      "Epoch   9/30: 100%|██████████| 703/703 [00:04<00:00, 159.93batch/s, Loss = 0.5232, AUC = 94.32%]\n",
      "Epoch  10/30: 100%|██████████| 703/703 [00:04<00:00, 157.99batch/s, Loss = 0.8063, AUC = 92.93%]\n",
      "Epoch  11/30: 100%|██████████| 703/703 [00:04<00:00, 156.19batch/s, Loss = 0.5744, AUC = 94.32%]\n",
      "Epoch  12/30: 100%|██████████| 703/703 [00:04<00:00, 157.67batch/s, Loss = 0.5807, AUC = 93.46%]\n",
      "Epoch  13/30: 100%|██████████| 703/703 [00:04<00:00, 157.21batch/s, Loss = 0.6980, AUC = 93.73%]\n",
      "Epoch  14/30: 100%|██████████| 703/703 [00:04<00:00, 158.74batch/s, Loss = 0.6960, AUC = 93.20%]\n",
      "Epoch  15/30: 100%|██████████| 703/703 [00:04<00:00, 159.21batch/s, Loss = 0.6860, AUC = 91.84%]\n",
      "Epoch  16/30: 100%|██████████| 703/703 [00:04<00:00, 158.44batch/s, Loss = 0.7304, AUC = 91.28%]\n",
      "Epoch  17/30: 100%|██████████| 703/703 [00:04<00:00, 158.24batch/s, Loss = 0.7741, AUC = 92.53%]\n",
      "Epoch  18/30: 100%|██████████| 703/703 [00:04<00:00, 157.42batch/s, Loss = 0.8614, AUC = 92.54%]\n",
      "Epoch  19/30: 100%|██████████| 703/703 [00:04<00:00, 157.04batch/s, Loss = 0.7140, AUC = 93.21%]\n",
      "Epoch  20/30: 100%|██████████| 703/703 [00:04<00:00, 156.44batch/s, Loss = 0.8702, AUC = 92.74%]\n",
      "Epoch  21/30: 100%|██████████| 703/703 [00:04<00:00, 157.32batch/s, Loss = 0.8768, AUC = 93.15%]\n",
      "Epoch  22/30: 100%|██████████| 703/703 [00:04<00:00, 156.81batch/s, Loss = 1.0101, AUC = 92.14%]\n",
      "Epoch  23/30: 100%|██████████| 703/703 [00:04<00:00, 157.67batch/s, Loss = 0.8170, AUC = 93.57%]\n",
      "Epoch  24/30: 100%|██████████| 703/703 [00:04<00:00, 156.82batch/s, Loss = 0.9055, AUC = 93.26%]\n",
      "Epoch  25/30: 100%|██████████| 703/703 [00:04<00:00, 157.16batch/s, Loss = 0.9402, AUC = 93.39%]\n",
      "Epoch  26/30: 100%|██████████| 703/703 [00:04<00:00, 156.56batch/s, Loss = 1.0954, AUC = 93.28%]\n",
      "Epoch  27/30: 100%|██████████| 703/703 [00:04<00:00, 156.16batch/s, Loss = 0.9263, AUC = 93.12%]\n",
      "Epoch  28/30: 100%|██████████| 703/703 [00:04<00:00, 157.80batch/s, Loss = 1.1077, AUC = 93.27%]\n",
      "Epoch  29/30: 100%|██████████| 703/703 [00:04<00:00, 157.16batch/s, Loss = 1.2047, AUC = 92.68%]\n",
      "Epoch  30/30: 100%|██████████| 703/703 [00:04<00:00, 158.26batch/s, Loss = 1.3361, AUC = 92.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time = 140.17s, best validation AUC = 94.81% at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 781/781 [00:04<00:00, 176.52batch/s, Loss = 0.3609, AUC = 92.90%]\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_val_dataloader, imdb_test_dataloader, num_classes=2, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T14:25:29.652105Z",
     "iopub.status.busy": "2023-08-27T14:25:29.651957Z",
     "iopub.status.idle": "2023-08-27T14:27:37.203618Z",
     "shell.execute_reply": "2023-08-27T14:27:37.203120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 703/703 [00:08<00:00, 78.31batch/s, Loss = 0.6904, AUC = 54.57%] \n",
      "Epoch   2/30: 100%|██████████| 703/703 [00:03<00:00, 183.14batch/s, Loss = 0.6843, AUC = 59.06%]\n",
      "Epoch   3/30: 100%|██████████| 703/703 [00:03<00:00, 182.05batch/s, Loss = 0.5915, AUC = 79.31%]\n",
      "Epoch   4/30: 100%|██████████| 703/703 [00:03<00:00, 181.99batch/s, Loss = 0.4942, AUC = 85.90%]\n",
      "Epoch   5/30: 100%|██████████| 703/703 [00:03<00:00, 181.91batch/s, Loss = 0.4596, AUC = 88.95%]\n",
      "Epoch   6/30: 100%|██████████| 703/703 [00:03<00:00, 184.21batch/s, Loss = 0.4069, AUC = 91.04%]\n",
      "Epoch   7/30: 100%|██████████| 703/703 [00:03<00:00, 184.09batch/s, Loss = 0.3745, AUC = 92.02%]\n",
      "Epoch   8/30: 100%|██████████| 703/703 [00:03<00:00, 182.92batch/s, Loss = 0.3801, AUC = 92.36%]\n",
      "Epoch   9/30: 100%|██████████| 703/703 [00:03<00:00, 181.71batch/s, Loss = 0.4106, AUC = 92.84%]\n",
      "Epoch  10/30: 100%|██████████| 703/703 [00:03<00:00, 184.05batch/s, Loss = 0.4546, AUC = 93.38%]\n",
      "Epoch  11/30: 100%|██████████| 703/703 [00:03<00:00, 182.57batch/s, Loss = 0.5097, AUC = 92.62%]\n",
      "Epoch  12/30: 100%|██████████| 703/703 [00:03<00:00, 182.61batch/s, Loss = 0.5701, AUC = 93.39%]\n",
      "Epoch  13/30: 100%|██████████| 703/703 [00:03<00:00, 183.79batch/s, Loss = 0.6103, AUC = 93.04%]\n",
      "Epoch  14/30: 100%|██████████| 703/703 [00:03<00:00, 183.54batch/s, Loss = 0.6691, AUC = 92.97%]\n",
      "Epoch  15/30: 100%|██████████| 703/703 [00:03<00:00, 186.09batch/s, Loss = 0.6477, AUC = 93.06%]\n",
      "Epoch  16/30: 100%|██████████| 703/703 [00:03<00:00, 185.04batch/s, Loss = 0.7111, AUC = 92.93%]\n",
      "Epoch  17/30: 100%|██████████| 703/703 [00:03<00:00, 182.64batch/s, Loss = 0.7569, AUC = 92.70%]\n",
      "Epoch  18/30: 100%|██████████| 703/703 [00:03<00:00, 184.77batch/s, Loss = 0.7895, AUC = 92.71%]\n",
      "Epoch  19/30: 100%|██████████| 703/703 [00:03<00:00, 183.73batch/s, Loss = 0.7610, AUC = 92.34%]\n",
      "Epoch  20/30: 100%|██████████| 703/703 [00:03<00:00, 182.82batch/s, Loss = 0.7319, AUC = 92.46%]\n",
      "Epoch  21/30: 100%|██████████| 703/703 [00:03<00:00, 185.46batch/s, Loss = 0.8053, AUC = 91.17%]\n",
      "Epoch  22/30: 100%|██████████| 703/703 [00:03<00:00, 184.36batch/s, Loss = 0.9088, AUC = 88.46%]\n",
      "Epoch  23/30: 100%|██████████| 703/703 [00:03<00:00, 181.80batch/s, Loss = 0.9261, AUC = 83.26%]\n",
      "Epoch  24/30: 100%|██████████| 703/703 [00:03<00:00, 184.87batch/s, Loss = 1.0242, AUC = 83.18%]\n",
      "Epoch  25/30: 100%|██████████| 703/703 [00:03<00:00, 183.23batch/s, Loss = 0.8967, AUC = 86.91%]\n",
      "Epoch  26/30: 100%|██████████| 703/703 [00:03<00:00, 182.23batch/s, Loss = 0.9075, AUC = 87.37%]\n",
      "Epoch  27/30: 100%|██████████| 703/703 [00:03<00:00, 181.95batch/s, Loss = 0.9740, AUC = 90.19%]\n",
      "Epoch  28/30: 100%|██████████| 703/703 [00:03<00:00, 184.41batch/s, Loss = 1.0757, AUC = 90.75%]\n",
      "Epoch  29/30: 100%|██████████| 703/703 [00:03<00:00, 183.27batch/s, Loss = 1.1052, AUC = 90.12%]\n",
      "Epoch  30/30: 100%|██████████| 703/703 [00:03<00:00, 182.48batch/s, Loss = 1.1350, AUC = 90.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time = 120.23s, best validation AUC = 93.39% at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 781/781 [00:04<00:00, 188.65batch/s, Loss = 0.6430, AUC = 91.69%]\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=8, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=4)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_val_dataloader, imdb_test_dataloader, num_classes=2, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
