{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T19:38:45.406758Z",
     "iopub.status.busy": "2023-08-26T19:38:45.406480Z",
     "iopub.status.idle": "2023-08-26T19:38:55.881166Z",
     "shell.execute_reply": "2023-08-26T19:38:55.880761Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 12:38:46.273497: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-08-26 12:38:46.273523: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-08-26 12:38:46.273539: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-26 12:38:47.837952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /global/common/software/m4392/conda/gsoc/lib/python3.11/site-packages/tensorflow/python/ops/distributions/bernoulli.py:165: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')  # Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.random.set_seed(42)  # For reproducibility.\n",
    "\n",
    "from quantum_transformers.datasets import get_imdb_dataloaders\n",
    "from quantum_transformers.training import train_and_evaluate\n",
    "from quantum_transformers.transformers import Transformer\n",
    "\n",
    "data_dir = '/global/cfs/cdirs/m4392/salcc/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T19:38:55.883534Z",
     "iopub.status.busy": "2023-08-26T19:38:55.883087Z",
     "iopub.status.idle": "2023-08-26T19:38:56.129850Z",
     "shell.execute_reply": "2023-08-26T19:38:56.129471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0 NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "for d in jax.devices():\n",
    "    print(d, d.device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T19:38:56.131454Z",
     "iopub.status.busy": "2023-08-26T19:38:56.131318Z",
     "iopub.status.idle": "2023-08-26T19:40:33.531785Z",
     "shell.execute_reply": "2023-08-26T19:40:33.531263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19169\n",
      "[  141  1693    15   139   161   123   631    34    34     4     4     4\n",
      "     4     4     4   218    99   220  1473  1848    15   150   241    50\n",
      "   180    10    61   193   101    10   329   156   645    17   112   478\n",
      "    10    61   119   414   103   514    97  1254   648    17    31   100\n",
      "    18    33    31   100    18    33    42   691    97   599   992  4916\n",
      " 12468   135   230  3431   192    42   691    97   156   472   169    15\n",
      "   126   230   113    42   156   472  2461   107   187    98   446    96\n",
      "   605   187    15    96    95  6665 17703   276   124  3424   187   510\n",
      "   136   158   156   472  5741    17   102   172   803    15    95   315\n",
      "   243    99   156   472    17    31   100    18    33    31   100    18\n",
      "    33   112   213   101   138    98   119   167   145   150  2019    96\n",
      "    95 15091   142    10    61   699   232     4     4    96   123   251\n",
      "    10    61     4    50   213    15   140    97   158   509   161   256\n",
      "    15   129   139    98   858    98    95  2070     5   661     5    96\n",
      "    95   599   887    15   110    15 15725    15   103   105   277  2156\n",
      "  1090   710    17    31   100    18    33    31   100    18    33   121\n",
      "    50   142   224    99   171   114   196   103   514    56 15646    17\n",
      "   101    99   114   386   220   613    17     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "good lord , what were they thinking ? ? ! ! ! ! ! ! here is your spoiler warning , even though i don ' t think it ' ll really matter . you won ' t be seeing this piece of trash anyway . < br / > < br / > a group of handpuppets go chasing after a group of really stupid people , who go on a really stupid hunt for them to try and kill them , and the puppets complicate things by letting them live out their really stupid fantasies . in other words , the whole thing is really stupid . < br / > < br / > you know it has to be bad when even mike and the bots can ' t save something ! ! and they didn ' t ! i know , some of their lines were funny , like what to add to the sign \" hit \" and the hand comments , but , geez , this was pretty dang sad . < br / > < br / > all i can say is do not watch this piece o crud . it is not worth your eyes . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "(imdb_train_dataloader, imdb_valid_dataloader), vocab, tokenizer = get_imdb_dataloaders(batch_size=32, data_dir=data_dir, max_vocab_size=20_000, max_seq_len=512)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "first_batch = next(iter(imdb_train_dataloader))\n",
    "print(first_batch[0][0])\n",
    "print(' '.join(map(bytes.decode, tokenizer.detokenize(first_batch[0])[0].numpy().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T19:40:33.533583Z",
     "iopub.status.busy": "2023-08-26T19:40:33.533388Z",
     "iopub.status.idle": "2023-08-26T19:45:01.215783Z",
     "shell.execute_reply": "2023-08-26T19:45:01.215347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:14<00:00, 53.37batch/s, Loss = 0.3567, AUC = 93.40%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:08<00:00, 93.73batch/s, Loss = 0.3244, AUC = 94.18%] \n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:07<00:00, 98.54batch/s, Loss = 0.3559, AUC = 93.58%] \n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:08<00:00, 97.39batch/s, Loss = 0.4501, AUC = 92.85%] \n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:08<00:00, 90.03batch/s, Loss = 0.5160, AUC = 92.42%] \n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:08<00:00, 90.49batch/s, Loss = 0.5915, AUC = 91.96%] \n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:08<00:00, 92.45batch/s, Loss = 0.6693, AUC = 91.72%] \n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:08<00:00, 96.69batch/s, Loss = 0.7665, AUC = 90.80%] \n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 98.26batch/s, Loss = 0.6940, AUC = 91.59%] \n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:08<00:00, 88.74batch/s, Loss = 0.7482, AUC = 91.50%] \n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:08<00:00, 97.44batch/s, Loss = 0.7525, AUC = 89.48%] \n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:08<00:00, 91.32batch/s, Loss = 0.7736, AUC = 91.45%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:08<00:00, 89.83batch/s, Loss = 0.8615, AUC = 90.59%] \n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:08<00:00, 91.07batch/s, Loss = 0.8921, AUC = 89.89%] \n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:08<00:00, 96.68batch/s, Loss = 0.9302, AUC = 90.78%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:08<00:00, 94.33batch/s, Loss = 0.8856, AUC = 90.76%] \n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:08<00:00, 92.92batch/s, Loss = 0.9897, AUC = 90.45%] \n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:08<00:00, 89.02batch/s, Loss = 0.9190, AUC = 90.17%] \n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:07<00:00, 100.74batch/s, Loss = 0.9084, AUC = 90.56%]\n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:07<00:00, 98.92batch/s, Loss = 0.8168, AUC = 90.51%] \n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:08<00:00, 89.98batch/s, Loss = 0.9268, AUC = 90.03%] \n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:08<00:00, 96.55batch/s, Loss = 0.7968, AUC = 90.59%] \n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:08<00:00, 90.93batch/s, Loss = 0.8818, AUC = 90.76%] \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:07<00:00, 99.32batch/s, Loss = 0.9627, AUC = 90.03%] \n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:08<00:00, 92.69batch/s, Loss = 1.1859, AUC = 88.68%] \n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:07<00:00, 97.92batch/s, Loss = 1.0195, AUC = 89.14%] \n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:08<00:00, 96.83batch/s, Loss = 1.0816, AUC = 88.82%] \n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:08<00:00, 94.95batch/s, Loss = 1.0022, AUC = 90.01%] \n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:08<00:00, 89.23batch/s, Loss = 1.1434, AUC = 89.30%] \n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 100.22batch/s, Loss = 1.0221, AUC = 90.36%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 255.01s\n",
      "BEST AUC = 94.18% AT EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=64, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=32)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T19:45:01.222288Z",
     "iopub.status.busy": "2023-08-26T19:45:01.221857Z",
     "iopub.status.idle": "2023-08-26T19:48:52.507140Z",
     "shell.execute_reply": "2023-08-26T19:48:52.506655Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/30: 100%|██████████| 781/781 [00:12<00:00, 62.41batch/s, Loss = 0.5926, AUC = 75.47%] \n",
      "Epoch   2/30: 100%|██████████| 781/781 [00:07<00:00, 107.53batch/s, Loss = 0.5297, AUC = 82.58%]\n",
      "Epoch   3/30: 100%|██████████| 781/781 [00:06<00:00, 111.63batch/s, Loss = 0.4770, AUC = 85.74%]\n",
      "Epoch   4/30: 100%|██████████| 781/781 [00:07<00:00, 102.40batch/s, Loss = 0.4541, AUC = 87.43%]\n",
      "Epoch   5/30: 100%|██████████| 781/781 [00:07<00:00, 105.32batch/s, Loss = 0.4325, AUC = 88.76%]\n",
      "Epoch   6/30: 100%|██████████| 781/781 [00:06<00:00, 113.64batch/s, Loss = 0.4267, AUC = 89.59%]\n",
      "Epoch   7/30: 100%|██████████| 781/781 [00:06<00:00, 111.68batch/s, Loss = 0.4741, AUC = 89.46%]\n",
      "Epoch   8/30: 100%|██████████| 781/781 [00:07<00:00, 106.87batch/s, Loss = 0.4302, AUC = 90.49%]\n",
      "Epoch   9/30: 100%|██████████| 781/781 [00:07<00:00, 100.48batch/s, Loss = 0.4258, AUC = 90.73%]\n",
      "Epoch  10/30: 100%|██████████| 781/781 [00:06<00:00, 113.62batch/s, Loss = 0.4365, AUC = 90.93%]\n",
      "Epoch  11/30: 100%|██████████| 781/781 [00:07<00:00, 107.46batch/s, Loss = 0.4886, AUC = 90.97%]\n",
      "Epoch  12/30: 100%|██████████| 781/781 [00:07<00:00, 98.93batch/s, Loss = 0.4769, AUC = 91.03%] \n",
      "Epoch  13/30: 100%|██████████| 781/781 [00:07<00:00, 102.09batch/s, Loss = 0.5076, AUC = 90.99%]\n",
      "Epoch  14/30: 100%|██████████| 781/781 [00:07<00:00, 106.84batch/s, Loss = 0.5391, AUC = 90.89%]\n",
      "Epoch  15/30: 100%|██████████| 781/781 [00:07<00:00, 99.11batch/s, Loss = 0.5479, AUC = 90.95%] \n",
      "Epoch  16/30: 100%|██████████| 781/781 [00:07<00:00, 109.73batch/s, Loss = 0.5885, AUC = 90.91%]\n",
      "Epoch  17/30: 100%|██████████| 781/781 [00:07<00:00, 101.27batch/s, Loss = 0.5997, AUC = 90.61%]\n",
      "Epoch  18/30: 100%|██████████| 781/781 [00:07<00:00, 107.94batch/s, Loss = 0.6302, AUC = 90.86%]\n",
      "Epoch  19/30: 100%|██████████| 781/781 [00:07<00:00, 105.70batch/s, Loss = 0.6622, AUC = 90.53%]\n",
      "Epoch  20/30: 100%|██████████| 781/781 [00:07<00:00, 103.22batch/s, Loss = 0.6633, AUC = 90.75%]\n",
      "Epoch  21/30: 100%|██████████| 781/781 [00:07<00:00, 110.09batch/s, Loss = 0.6577, AUC = 90.72%]\n",
      "Epoch  22/30: 100%|██████████| 781/781 [00:07<00:00, 102.21batch/s, Loss = 0.6820, AUC = 90.65%]\n",
      "Epoch  23/30: 100%|██████████| 781/781 [00:07<00:00, 99.06batch/s, Loss = 0.6810, AUC = 90.71%] \n",
      "Epoch  24/30: 100%|██████████| 781/781 [00:07<00:00, 100.54batch/s, Loss = 0.6937, AUC = 90.74%]\n",
      "Epoch  25/30: 100%|██████████| 781/781 [00:07<00:00, 105.12batch/s, Loss = 0.6979, AUC = 90.68%]\n",
      "Epoch  26/30: 100%|██████████| 781/781 [00:07<00:00, 102.67batch/s, Loss = 0.7251, AUC = 90.56%]\n",
      "Epoch  27/30: 100%|██████████| 781/781 [00:07<00:00, 105.37batch/s, Loss = 0.7069, AUC = 90.59%]\n",
      "Epoch  28/30: 100%|██████████| 781/781 [00:07<00:00, 102.52batch/s, Loss = 0.7250, AUC = 90.55%]\n",
      "Epoch  29/30: 100%|██████████| 781/781 [00:07<00:00, 110.19batch/s, Loss = 0.7031, AUC = 90.55%]\n",
      "Epoch  30/30: 100%|██████████| 781/781 [00:07<00:00, 98.13batch/s, Loss = 0.7282, AUC = 90.60%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME = 228.20s\n",
      "BEST AUC = 91.03% AT EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(num_tokens=len(vocab), max_seq_len=512, num_classes=2, hidden_size=8, num_heads=2, num_transformer_blocks=4, mlp_hidden_size=4)\n",
    "train_and_evaluate(model, imdb_train_dataloader, imdb_valid_dataloader, num_classes=2, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
